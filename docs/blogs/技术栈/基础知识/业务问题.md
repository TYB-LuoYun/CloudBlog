---
title: 业务问题
date: 2024/04/11
tags:
 - 基础知识
categories:
 - 基础知识
---



## 
聚合支付的实现，微信的H5，支付宝App扫码





## 防重幂等性问题  ---如何防止抖动，重复下订单
重复提交原因
其实原因无外乎两种：

一种是由于用户在短时间内多次点击下单按钮，或浏览器刷新按钮导致。
另一种则是由于Nginx或类似于SpringCloud Gateway的网关层，进行超时重试造成的。


Order 服务调用 Pay 服务，刚好网络超时，然后 Order 服务开始重试机制，于是 Pay 服务对同一支付请求，就接收到了两次，而且因为轮询负载均衡算法，落在了不同业务节点！所以一个分布式系统接口，须保证幂等性。

幂等性要做到:
1每个请求须有唯一标识
2每次处理完请求后，须有记录标识该请求已被处理
3每次接收请求时，判断之前是否处理过


解决:
1提交订单按钮置灰
2预生成全局唯一订单号,利用数据库的唯一索引特性，在插入订单记录时，如果该“全局唯一的订单号”重复，记录会插入失败
3将一些重要的参数比如用户id，商品id，价格，数量 进行md5 或者 拼接 作为 分布式锁的 键


## redis或mongdb存缓存与存库的一致性问题
先更新数据库，再更新缓存，加事务，整个方法执行完成后再提交


这样的坏处在于重要的数据因为redis而没成功

其次采用MQ的异步重试方案：
1）写数据时，先将数据写入数据库中，写入成功后通过发送消息的方式将数据写入MQ中进行备份。

2）更新/删除到缓存时，如果更新/删除缓存成功，则删除MQ中的备份数据；如果更新/删除缓存失败，则使用MQ中的备份数据进行异步重试。

## 防⽌库存超卖 
数据库锁：select xxx for update；悲观锁，在事务提交之前，其他事务可以读取被锁定的行，但不能修改或删除这些行
分布式锁: 可以阻塞等待一段时间，再报错
乐观锁：使⽤带版本号的更新。每个线程都可以并发修改，但在并发时，只有⼀个线程会修改成功，其它会返回失败。


总结：

总的来说，不能把压⼒放在数据库上，所以使⽤ “select xxx for update” 的⽅式在⾼并发的场景下是不可⾏的。FIFO 同步队列的⽅式，可以结合库存限制队列⻓，但是在库存较多的场景下，⼜不太适⽤。所以相对来说，我会倾向于选择：乐观锁 / 缓存锁 / 分布式锁的⽅式。





## ABA 问题
业务: 一个请求修改A，修改成功但是没有响应，此时用户发起了另一个请求修改成B ，但是上一个请求会重试 又会修改A    解决方案: 查询更新时候带版本号，更新成功后版本号加1(UPDATE orders set tracking_number = 666, version = version + 1 WHERE version = 8;)
线程: 线程1读取共享变量值A，并执行一些计算，然后线程2将该共享变量的值更改为B，最后线程2又将其值改回A, 在CAS操作中，它检查共享变量的值是否与预期的值A相同，结果是相同的，所以线程1错误地认为没有其他线程修改过这个值，并执行更新操作

 避免ABA问题的解决方案：
 版本号或时间戳：对数据进行版本控制或标记时间戳
 原子引用：使用原子引用类（AtomicReference等）来保证原子性操作



## 主键问题

雪花ID：
优点:
1.分布式环境下唯一性
雪花ID在分布式系统中生成唯一的ID，可以满足分布式环境下的需求。
缺点：
1.依赖于机器时钟
雪花ID的生成依赖于机器的时钟，如果时钟回拨或者时钟不同步，可能会导致生成的ID不唯一。
2.存储空间较大
雪花ID占用的存储空间较大，通常为64位，如果作为主键，会占用更多的存储空间。
3.查询效率低
由于雪花ID是随机生成的，不具有顺序性，导致索引效率较低。


在MySQL中，使用自增整数作为主键是一种常见的做法，因为它具有较小的存储空间、高效的索引和自动增长的特性。

相比之下，使用UUID或者雪花ID作为主键可能会导致性能下降、存储空间浪费和索引效率降低等问题

## MySQL分组查询每组最新的一条数据

- 先排序后分组(很慢)，排序的时候使用limit 数量就是count的数量
- 数据量很大，业务层面优化，新增字段标识，isnewdata,bit型或者int型就好，每次在表中提交数据时，事务中先将要提交的数据所涉及的id，将历史数据isnewdata=1的更新为0，新提交的数据，isnewdata为1，然后增加一个索引isnewdata，或者如果需要和其他表关联的时候，增加复合索引，性能一下就上来了。
- 使用 MAX(id) 查询，只适用于自增ID和创建时间排序一致，查询性能最优

使用MAX(id)+分组查询可以查询出每组中最大的id，然后通过每组最大数据id集合关联查出数据即可，因为我这里的业务数据是有序插入的，使用主键自增id和create_time结果是一样的而且使用id查询效率更高，如果没有唯一且有序的id可以替代create_time那么就用上面两个方法。
PS：这里使用内连接查询而不使用 IN 查询是因为我测试时发现连接查询会比 IN 查询性能要高50%以上，这个和底层查询机制有关有兴趣可以查看 IN 查询和连接查询的执行计划。

```
 SELECT
	t1.* 
FROM
	customer_wallet_detail t1
	INNER JOIN ( SELECT MAX( id ) AS id FROM customer_wallet_detail GROUP BY customer_id ) t2 ON t1.id = t2.id
```



![image-20240703155734216](D:\tyb\code\TYB-LuoYun.github.io\docs\blogs\技术栈\基础知识\业务问题.assets\image-20240703155734216.png)















